{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Index\n",
    "\n",
    "In this notebook showcase how you can use the dense index with Baguetter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We showcase here the usage of our inference engine [Ofen](https://github/mixedbread-ai/ofen) for generating the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"ofen[torch]==0.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ofen.models import TextEncoder\n",
    "from baguetter.indices import USearchDenseIndex\n",
    "from baguetter.evaluation import evaluate_retrievers, HFDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = HFDataset(\"mteb/scidocs\")\n",
    "\n",
    "model = TextEncoder.from_pretrained(\"mixedbread-ai/mxbai-embed-large-v1\")\n",
    "## Convert model to half precision (FP16) for efficiency\n",
    "model.half()\n",
    "\n",
    "\n",
    "# Define the embedding function expected by the USearchDenseIndex.\n",
    "# Alternatively, you can compute the embeddings yourself and add them to the index.\n",
    "def embed_fn(text: list[str], is_query: bool = False, show_progress: bool = False):\n",
    "    if is_query:\n",
    "        text = [f\"Represent this sentence for searching relevant passages: {query}\" for query in text]\n",
    "    return model.encode(text, batch_size=256, show_progress=show_progress).embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create the dense index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = USearchDenseIndex(embed_fn=embed_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Add documents and search the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add: 100%|██████████| 100/100 [00:00<00:00, 10812.85vector/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "usearch.Index\n",
       "- config\n",
       "-- data type: ScalarKind.F16\n",
       "-- dimensions: 1024\n",
       "-- metric: MetricKind.Cos\n",
       "-- multi: False\n",
       "-- connectivity: 16\n",
       "-- expansion on addition :128 candidates\n",
       "-- expansion on search: 64 candidates\n",
       "- binary\n",
       "-- uses OpenMP: 0\n",
       "-- uses SimSIMD: 1\n",
       "-- supports half-precision: 1\n",
       "-- uses hardware acceleration: haswell\n",
       "- state\n",
       "-- size: 100 vectors\n",
       "-- memory usage: 21,006,272 bytes\n",
       "-- max level: 0\n",
       "--- 0. 100 nodes"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ids, docs = ds.get_corpus()\n",
    "\n",
    "index.add_many(doc_ids[:100], docs[:100], show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SearchResults(keys=['632589828c8b9fca2c3a59e97451fde8fa7d188d', '51317b6082322a96b4570818b7a5ec8b2e330f2f', '506172b0e0dd4269bdcfe96dda9ea9d8602bbfb6', '2a047d8c4c2a4825e0f0305294e7da14f8de6fd3', '86e87db2dab958f1bd5877dc7d5b8105d6e31e46', 'c108437a57bd8f8eaed9e26360ee100074e3f3fc', '24ff5027e7042aeead47ef3071f1a023243078bb', '8e508720cdb495b7821bf6e43c740eeb5f3a444a', '2ae40898406df0a3732acc54f147c1d377f54e2a', '55ca165fa6091973674b12ea8fa3f1a3a1e50a6d'], scores=array([0.988507  , 0.7668916 , 0.7029923 , 0.69961214, 0.68070495,\n",
       "       0.6354893 , 0.62746024, 0.6235753 , 0.6081617 , 0.6014837 ],\n",
       "      dtype=float32), normalized=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(docs[0], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate dense retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating  1 retrievers...\n",
      "---------------------------------------------------------------\n",
      "Datasets:  ['mteb/scidocs']\n",
      "Top K:  100\n",
      "Metrics:  ['ndcg@1', 'ndcg@5', 'ndcg@10', 'precision@1', 'precision@5', 'precision@10', 'mrr@1', 'mrr@5', 'mrr@10']\n",
      "Ignore identical IDs:  True\n",
      "\n",
      "Evaluating Dataset: mteb/scidocs\n",
      "---------------------------------------------------------------\n",
      "Starting Adding 25657 documents to usearch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 101/101 [00:46<00:00,  2.15it/s]\n",
      "Add: 100%|██████████| 25657/25657 [00:00<00:00, 44663.61vector/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 25657 documents to usearch took 47.65 seconds\n",
      "Starting Searching 1000 queries with usearch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 4/4 [00:00<00:00,  7.39it/s]\n",
      "Search: 100%|██████████| 1000/1000 [00:00<00:00, 4464.11vector/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 1000 queries with usearch took 0.95 seconds\n",
      "\n",
      "Report (rounded):\n",
      "---------------------------------------------------------------\n",
      "#    Model      NDCG@1    NDCG@5    NDCG@10    P@1    P@5    P@10    MRR@1    MRR@5    MRR@10\n",
      "---  -------  --------  --------  ---------  -----  -----  ------  -------  -------  --------\n",
      "a    usearch     0.254     0.193      0.231  0.254  0.173   0.121    0.254    0.362     0.376\n"
     ]
    }
   ],
   "source": [
    "result = evaluate_retrievers(\n",
    "    datasets=[ds],\n",
    "    retriever_factories={\n",
    "        \"usearch\": lambda: USearchDenseIndex(\n",
    "            embed_fn=embed_fn\n",
    "        )\n",
    "    }\n",
    ")\n",
    "result.save(\"eval_results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
